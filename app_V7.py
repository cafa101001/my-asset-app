import streamlit as st
import pandas as pd
from datetime import datetime, timedelta

import plotly.express as px
import plotly.graph_objects as go

from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import json
import streamlit.components.v1 as components
import requests
import re
from bs4 import BeautifulSoup

# --- é—œéµåŒ¯å…¥ ---
# å¼•å…¥ utils ä¸­çš„ update_supabase_session ä¾†åŒæ­¥æ¬Šé™
from utils import supabase as data_client, get_market_data, update_supabase_session

# å˜—è©¦åŒ¯å…¥ Supabase Client è¨­å®šï¼Œè‹¥ç‰ˆæœ¬éèˆŠå‰‡æç¤º
try:
    from supabase import create_client
    try:
        # éƒ¨åˆ†ç‰ˆæœ¬ç›´æ¥æä¾› ClientOptions
        from supabase import ClientOptions  # type: ignore
    except Exception:
        # æ–°ç‰ˆå¸¸è¦‹è·¯å¾‘
        from supabase.lib.client_options import ClientOptions  # type: ignore
except Exception:
    st.error("âŒ åµæ¸¬åˆ° Supabase å¥—ä»¶ç‰ˆæœ¬éèˆŠæˆ–æœªå®‰è£ã€‚è«‹ç¢ºèª requirements.txt å…§æœ‰ `supabase`ï¼Œä¸¦é‡æ–°éƒ¨ç½²ã€‚")
    st.stop()

from logic import fetch_all_data, calculate_detailed_metrics, clean_df, save_daily_snapshot

# --- 1. é é¢åŸºç¤è¨­å®š ---
st.set_page_config(page_title="å…¨çƒè³‡ç”¢ç®¡ç†ç³»çµ± V7.5", layout="wide")

# ==========================================
#      ğŸ‡¹ğŸ‡¼ å°è‚¡ä»£ç¢¼ -> ä¸­æ–‡åç¨±ï¼ˆå¿«å–ï¼‰
# ==========================================

def _norm_twse_text(s: str) -> str:
    s = str(s).replace("\u3000", " ").replace("ã€€", " ").strip()
    s = re.sub(r"\s+", " ", s)
    return s

def _parse_isin_table(html: str) -> dict:
    """è§£æ TWSE ISIN æ¸…å–®é ï¼šå–å‡ºã€ä»£è™Ÿ -> ä¸­æ–‡åç¨±ã€"""
    mp: dict = {}
    soup = BeautifulSoup(html, "html.parser")

    tables = soup.find_all("table")
    if not tables:
        return mp

    # å„ªå…ˆæ‰¾å«ã€Œæœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±ã€å­—æ¨£çš„è¡¨æ ¼
    target = None
    for tbl in tables:
        if "æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±" in tbl.get_text():
            target = tbl
            break

    # æ‰¾ä¸åˆ°å°±å– tr æœ€å¤šçš„é‚£å¼µè¡¨ï¼ˆä¿åº•ï¼‰
    if target is None:
        target = max(tables, key=lambda t: len(t.find_all("tr")))

    for tr in target.find_all("tr"):
        tds = tr.find_all("td")
        if not tds:
            continue

        cells = [_norm_twse_text(td.get_text(" ", strip=True)) for td in tds]
        if not cells:
            continue

        first = cells[0]
        if not first:
            continue
        if "æœ‰åƒ¹è­‰åˆ¸ä»£è™ŸåŠåç¨±" in first:
            continue

        code = None
        name = None

        # Case 1ï¼šç¬¬ä¸€æ¬„å°±æ˜¯ã€Œ2330 å°ç©é›»ã€é€™ç¨®æ ¼å¼
        m = re.match(r"^([0-9A-Za-z]{4,8})\s+(.+)$", first)
        if m:
            c = m.group(1).strip().upper()
            n = m.group(2).strip()
            if any(ch.isdigit() for ch in c) and n:
                code, name = c, n

        # Case 2ï¼šæ¬„ä½åˆ†é–‹ï¼ˆç¬¬ä¸€æ¬„æ˜¯ä»£ç¢¼ã€ç¬¬äºŒæ¬„æ˜¯åç¨±ï¼‰
        if code is None and re.fullmatch(r"[0-9A-Za-z]{4,8}", first) and len(cells) >= 2:
            c = first.strip().upper()
            n = cells[1].strip()
            if any(ch.isdigit() for ch in c) and n:
                code, name = c, n

        if not code or not name:
            continue

        mp[code] = name
        if code.isdigit():
            mp[f"{code}.TW"] = name

    return mp

@st.cache_data(ttl=86400, show_spinner=False)
def _load_twse_stock_map(_cache_bust: str = "v3") -> dict:
    """æŠ“å–ä¸Šå¸‚/ä¸Šæ«ƒæ¸…å–®ä¸¦åˆä½µï¼ˆæˆåŠŸæ‰æœƒè¢« cacheï¼›å¤±æ•—æœƒä¸Ÿä¾‹å¤–é¿å… cache ç©ºçµæœï¼‰"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36",
        "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8",
    }

    mp: dict = {}

    # strMode=2ï¼šä¸Šå¸‚ã€ETF ç­‰ï¼›strMode=4ï¼šä¸Šæ«ƒ
    for mode in ("2", "4"):
        url = f"https://isin.twse.com.tw/isin/C_public.jsp?strMode={mode}"
        r = requests.get(url, headers=headers, timeout=30)
        # ISIN æ¸…å–®é å¤šç‚º Big5ï¼›é¿å… requests èª¤åˆ¤æˆ ISO-8859-1
        if (not r.encoding) or (r.encoding.lower() == "iso-8859-1"):
            r.encoding = "big5"
        mp.update(_parse_isin_table(r.text))

    # é˜²å‘†ï¼šå¦‚æœå¤ªå°ï¼Œä»£è¡¨æŠ“å–/è§£æå¤±æ•—ï¼Œä¸è¦ cache
    if len(mp) < 500:
        raise RuntimeError(f"TWSE mapping too small: {len(mp)}")

    return mp

def get_twse_stock_map() -> dict:
    """å›å‚³å°è‚¡ä»£ç¢¼->ä¸­æ–‡åç¨±å°ç…§è¡¨ï¼ˆå¿«å– 1 å¤©ï¼‰ã€‚"""
    try:
        # é€é cache_bust ç‰ˆæœ¬å­—ä¸²ç¢ºä¿éƒ¨ç½²æ›´æ–°å¾Œæœƒé‡æ–°æŠ“å–
        return _load_twse_stock_map(_cache_bust="v3_2026-01-09")
    except Exception as e:
        # ä¸è¦ st.error ä»¥å…æ‰“æ–·æµç¨‹ï¼Œæ”¹ç”¨ log
        print(f"TWSE æ¸…å–®æŠ“å–/è§£æå¤±æ•—: {e}")
        return {}

@st.cache_data(ttl=86400, show_spinner=False)
def _twse_code_query(code: str) -> str:
    """è‹¥å…¨é‡æ¸…å–®æŠ“ä¸åˆ°ï¼Œç”¨ TWSE codeQuery ä»¥ä»£ç¢¼æŸ¥åç¨±ï¼ˆçµæœæœƒ cacheï¼‰ã€‚"""
    code = str(code).strip().upper().replace(".TW", "").replace(".TWO", "")
    if not code:
        return ""

    headers = {
        "User-Agent": "Mozilla/5.0",
        "Accept-Language": "zh-TW,zh;q=0.9,en;q=0.8",
    }
    url = f"https://www.twse.com.tw/zh/api/codeQuery?query={code}"
    r = requests.get(url, headers=headers, timeout=10)
    if r.status_code != 200:
        return ""
    try:
        j = r.json()
    except Exception:
        return ""

    sugs = j.get("suggestions") or []
    for s in sugs:
        s = str(s)
        parts = s.split("\t")
        if parts and parts[0].strip() == code:
            if len(parts) > 1 and parts[1].strip():
                return parts[1].strip()

    # fallbackï¼šæœ‰äº›æ ¼å¼å¯èƒ½æ˜¯ã€Œ2330 å°ç©é›»ã€
    for s in sugs:
        ss = _norm_twse_text(s)
        if ss.startswith(code + " "):
            return ss[len(code) + 1 :].strip()

    return ""

def get_tw_stock_name(code: str):
    """å›å‚³å°è‚¡ä¸­æ–‡åç¨±ï¼›æŸ¥ä¸åˆ°å‰‡å›å‚³ None"""
    base = str(code).strip().upper().replace(".TW", "").replace(".TWO", "")
    if not base:
        return None

    mp = get_twse_stock_map()
    if mp:
        name = mp.get(base) or mp.get(f"{base}.TW")
        if name:
            return name

    # å…¨é‡æ¸…å–®æŠ“ä¸åˆ°æ™‚çš„ä¿åº•æŸ¥è©¢ï¼ˆå–®ç­†æŸ¥è©¢ä¹Ÿæœƒ cacheï¼‰
    qname = _twse_code_query(base)
    return qname if qname else None


def _format_dt_series(s: pd.Series) -> pd.Series:
    """æŠŠæ™‚é–“æ¬„ä½æ ¼å¼åŒ–ç‚º YYYY-MM-DD HH:MMï¼ˆæ”¯æ´ timezone-aware / naiveï¼‰"""
    dt = pd.to_datetime(s, errors="coerce")
    try:
        if getattr(dt.dt, "tz", None) is not None:
            dt = dt.dt.tz_convert("Asia/Taipei").dt.tz_localize(None)
    except Exception:
        pass
    return dt.dt.strftime("%Y-%m-%d %H:%M")

def _normalize_id(v):
    if v is None:
        return None
    try:
        if isinstance(v, float) and pd.isna(v):
            return None
    except Exception:
        pass
    try:
        return int(v)
    except Exception:
        return str(v)

def _safe_float(v, default=0.0):
    try:
        if v is None:
            return default
        if isinstance(v, float) and pd.isna(v):
            return default
        return float(v)
    except Exception:
        return default

def _delete_rows_by_ids(table_name: str, ids: list):
    """ä¾ id åˆªé™¤å¤šç­†è³‡æ–™ï¼ˆSupabase PostgRESTï¼‰"""
    ids = [i for i in ids if i is not None]
    if not ids:
        return
    try:
        data_client.table(table_name).delete().in_("id", ids).execute()
    except Exception:
        # fallback: é€ç­†åˆªé™¤
        for _id in ids:
            data_client.table(table_name).delete().eq("id", _id).execute()
# ==========================================
#      ğŸ“ Data Editor åŒæ­¥ï¼ˆç·¨è¼¯/åˆªé™¤ -> Supabaseï¼‰
# ==========================================

def _sync_liabilities(original_df: pd.DataFrame, edited_df_zh: pd.DataFrame):
    """åŒæ­¥ã€è² å‚µç®¡ç†ã€è¡¨æ ¼ï¼šæ”¯æ´ç·¨è¼¯ã€åˆªé™¤ã€ï¼ˆå¯é¸ï¼‰æ–°å¢"""
    if edited_df_zh is None:
        return

    inv = {"è² å‚µé¡åˆ¥": "category", "é …ç›®åç¨±": "name", "é‡‘é¡(TWD)": "amount"}
    df = edited_df_zh.rename(columns=inv).copy()

    if "id" not in df.columns:
        st.error("âŒ è² å‚µè¡¨æ ¼ç¼ºå°‘ id æ¬„ä½ï¼Œç„¡æ³•åŒæ­¥")
        return

    # 1) åˆªé™¤ï¼šåŸæœ¬æœ‰ã€ç¾åœ¨æ²’æœ‰çš„ id
    orig_ids = set()
    if original_df is not None and (not original_df.empty) and "id" in original_df.columns:
        orig_ids = set(_normalize_id(x) for x in original_df["id"].dropna())
    new_ids = set(_normalize_id(x) for x in df["id"].dropna())
    del_ids = [i for i in orig_ids if i not in new_ids]
    _delete_rows_by_ids("liabilities", del_ids)

    # 2) æ›´æ–° / æ–°å¢
    now_iso = datetime.now().isoformat()
    user_id = st.session_state.user_id

    for _, row in df.iterrows():
        rid = _normalize_id(row.get("id"))
        name = str(row.get("name") or "").strip()
        if not name:
            continue  # å¿½ç•¥ç©ºç™½åˆ—

        cat = str(row.get("category") or "").strip() or "å…¶ä»–"
        amt = _safe_float(row.get("amount"), 0.0)

        if rid is None:
            # æ–°å¢ï¼šç”¨ upsertï¼ˆé¿å…é‡è¤‡ nameï¼‰
            data_client.table("liabilities").upsert(
                {"user_id": user_id, "category": cat, "name": name, "amount": amt, "updated_at": now_iso},
                on_conflict="user_id, name",
            ).execute()
        else:
            data_client.table("liabilities").update(
                {"category": cat, "name": name, "amount": amt, "updated_at": now_iso}
            ).eq("id", rid).execute()

def _sync_liquidity(original_df: pd.DataFrame, edited_df_zh: pd.DataFrame):
    """åŒæ­¥ã€æµå‹•è³‡é‡‘ã€è¡¨æ ¼ï¼šæ”¯æ´ç·¨è¼¯ã€åˆªé™¤ã€ï¼ˆå¯é¸ï¼‰æ–°å¢"""
    if edited_df_zh is None:
        return

    inv = {"å¸³æˆ¶åç¨±": "account_name", "é‡‘é¡(TWD)": "amount"}
    df = edited_df_zh.rename(columns=inv).copy()

    if "id" not in df.columns:
        st.error("âŒ æµå‹•è³‡é‡‘è¡¨æ ¼ç¼ºå°‘ id æ¬„ä½ï¼Œç„¡æ³•åŒæ­¥")
        return

    orig_ids = set()
    if original_df is not None and (not original_df.empty) and "id" in original_df.columns:
        orig_ids = set(_normalize_id(x) for x in original_df["id"].dropna())
    new_ids = set(_normalize_id(x) for x in df["id"].dropna())
    del_ids = [i for i in orig_ids if i not in new_ids]
    _delete_rows_by_ids("liquidity", del_ids)

    now_iso = datetime.now().isoformat()
    user_id = st.session_state.user_id

    for _, row in df.iterrows():
        rid = _normalize_id(row.get("id"))
        acc = str(row.get("account_name") or "").strip()
        if not acc:
            continue

        amt = _safe_float(row.get("amount"), 0.0)

        if rid is None:
            data_client.table("liquidity").upsert(
                {"user_id": user_id, "account_name": acc, "amount": amt, "updated_at": now_iso},
                on_conflict="user_id, account_name",
            ).execute()
        else:
            data_client.table("liquidity").update(
                {"account_name": acc, "amount": amt, "updated_at": now_iso}
            ).eq("id", rid).execute()

def _sync_income_history(original_df: pd.DataFrame, edited_df_zh: pd.DataFrame):
    """åŒæ­¥ã€æ”¶å…¥ã€è¡¨æ ¼ï¼šæ”¯æ´ç·¨è¼¯ã€åˆªé™¤ã€ï¼ˆå¯é¸ï¼‰æ–°å¢"""
    if edited_df_zh is None:
        return

    df = edited_df_zh.copy()
    # é¡¯ç¤ºç”¨æ¬„ä½ï¼Œä¸å›å¯«è³‡æ–™åº«
    if "ä¸Šå‚³æ™‚é–“" in df.columns:
        df = df.drop(columns=["ä¸Šå‚³æ™‚é–“"])

    if "id" not in df.columns:
        st.error("âŒ æ”¶å…¥è¡¨æ ¼ç¼ºå°‘ id æ¬„ä½ï¼Œç„¡æ³•åŒæ­¥")
        return

    orig_ids = set()
    if original_df is not None and (not original_df.empty) and "id" in original_df.columns:
        orig_ids = set(_normalize_id(x) for x in original_df["id"].dropna())
    new_ids = set(_normalize_id(x) for x in df["id"].dropna())
    del_ids = [i for i in orig_ids if i not in new_ids]
    _delete_rows_by_ids("income_history", del_ids)

    user_id = st.session_state.user_id

    for _, row in df.iterrows():
        rid = _normalize_id(row.get("id"))
        ann = row.get("å¹´æ”¶å…¥")
        note = str(row.get("å‚™è¨»") or "").strip()

        if ann is None or (isinstance(ann, float) and pd.isna(ann)):
            # å¿½ç•¥ç©ºç™½åˆ—
            if rid is None:
                continue
            ann_val = None
        else:
            try:
                ann_val = int(float(ann))
            except Exception:
                ann_val = None

        if rid is None:
            if ann_val is None:
                continue
            data_client.table("income_history").insert(
                {"user_id": user_id, "ç´€éŒ„æ—¥æœŸ": datetime.now().isoformat(), "å¹´æ”¶å…¥": ann_val, "å‚™è¨»": note}
            ).execute()
        else:
            payload = {}
            if ann_val is not None:
                payload["å¹´æ”¶å…¥"] = ann_val
            payload["å‚™è¨»"] = note
            if payload:
                data_client.table("income_history").update(payload).eq("id", rid).execute()

def _sync_transactions(original_df: pd.DataFrame, edited_df: pd.DataFrame):
    """åŒæ­¥ã€äº¤æ˜“ã€è¡¨æ ¼ï¼šæ”¯æ´ç·¨è¼¯ã€åˆªé™¤ã€ï¼ˆå¯é¸ï¼‰æ–°å¢"""
    if edited_df is None:
        return

    df = edited_df.copy()
    # é¡¯ç¤ºç”¨æ¬„ä½ï¼Œä¸å›å¯«è³‡æ–™åº«
    if "å°è‚¡åç¨±" in df.columns:
        df = df.drop(columns=["å°è‚¡åç¨±"])

    if "id" not in df.columns:
        st.error("âŒ äº¤æ˜“è¡¨æ ¼ç¼ºå°‘ id æ¬„ä½ï¼Œç„¡æ³•åŒæ­¥")
        return

    orig_ids = set()
    if original_df is not None and (not original_df.empty) and "id" in original_df.columns:
        orig_ids = set(_normalize_id(x) for x in original_df["id"].dropna())
    new_ids = set(_normalize_id(x) for x in df["id"].dropna())
    del_ids = [i for i in orig_ids if i not in new_ids]
    _delete_rows_by_ids("transactions", del_ids)

    user_id = st.session_state.user_id

    for _, row in df.iterrows():
        rid = _normalize_id(row.get("id"))
        t_type = str(row.get("é¡å‹") or "").strip()
        t_cat = str(row.get("é¡åˆ¥") or "").strip()
        ticker = str(row.get("ä»£ç¢¼") or "").upper().strip()
        qty = _safe_float(row.get("æ•¸é‡"), 0.0)
        price = _safe_float(row.get("å–®åƒ¹"), 0.0)
        date_v = row.get("æ—¥æœŸ")

        # å¿½ç•¥ç©ºç™½åˆ—
        if not ticker or qty <= 0:
            if rid is None:
                continue

        try:
            date_iso = pd.to_datetime(date_v, errors="coerce").date().isoformat() if date_v else None
        except Exception:
            date_iso = None

        payload = {
            "user_id": user_id,
            "é¡å‹": t_type,
            "é¡åˆ¥": t_cat,
            "ä»£ç¢¼": ticker,
            "æ•¸é‡": qty,
            "å–®åƒ¹": price,
            "æ—¥æœŸ": date_iso,
        }

        # ç§»é™¤ Noneï¼Œé¿å…å¯«å…¥å¤±æ•—
        payload = {k: v for k, v in payload.items() if v is not None}

        if rid is None:
            data_client.table("transactions").insert(payload).execute()
        else:
            payload.pop("user_id", None)  # æ›´æ–°æ™‚ä¸å¿…å‹•åˆ° user_id
            data_client.table("transactions").update(payload).eq("id", rid).execute()

# ==========================================
#      ğŸ” ç™»å…¥é‚è¼¯ (Session Storage + Sync)
# ==========================================

# 1. åˆå§‹åŒ– Session State
if "user" not in st.session_state:
    st.session_state.user = None
if "user_id" not in st.session_state:
    st.session_state.user_id = None


class StreamlitSessionStorage:
    """è®“ supabase/auth-py èƒ½æŠŠ PKCE verifier èˆ‡ session token å­˜åœ¨ Streamlit çš„ session_state å…§ã€‚"""

    def __init__(self):
        if "supabase_auth_storage" not in st.session_state:
            st.session_state.supabase_auth_storage = {}

    def get_item(self, key):
        return st.session_state.supabase_auth_storage.get(key)

    def set_item(self, key, value):
        st.session_state.supabase_auth_storage[key] = value

    def remove_item(self, key):
        if key in st.session_state.supabase_auth_storage:
            del st.session_state.supabase_auth_storage[key]


# å»ºç«‹å°ˆç”¨æ–¼ç™»å…¥é©—è­‰çš„ Client
# ä½¿ç”¨ st.session_state æ­é… StreamlitSessionStorage ç¢ºä¿ç‹€æ…‹æŒä¹…åŒ–
if "auth_client" not in st.session_state:
    try:
        url = st.secrets["SUPABASE_URL"]
        key = st.secrets["SUPABASE_KEY"]
    except Exception:
        st.error("âŒ æ‰¾ä¸åˆ° SUPABASE_URL / SUPABASE_KEYã€‚è«‹åœ¨ Streamlit secrets è¨­å®šã€‚")
        st.stop()

    try:
        st.session_state.auth_client = create_client(
            url,
            key,
            options=ClientOptions(
                storage=StreamlitSessionStorage(),
                flow_type="pkce",
            ),
        )
    except Exception as e:
        st.error(f"âŒ Auth Client åˆå§‹åŒ–å¤±æ•—: {e}")
        st.stop()


def get_query_params():
    try:
        return st.query_params
    except Exception:
        return st.experimental_get_query_params()


def clear_url():
    try:
        st.query_params.clear()
    except Exception:
        st.experimental_set_query_params()


def _first(v):
    """æŠŠ query param çš„å€¼çµ±ä¸€æˆå–®ä¸€å­—ä¸²"""
    if v is None:
        return None
    if isinstance(v, list):
        return v[0] if v else None
    return v


def _find_code_verifier(storage: dict):
    """å¾ storage æ‰¾åˆ° (verifier_key, verifier_value)"""
    if not isinstance(storage, dict):
        return None, None

    # å…ˆå˜—è©¦å¸¸è¦‹ key
    common_keys = [
        "supabase.auth.token-code-verifier",
        "supabase.auth.token-code_verifier",
        "code_verifier",
        "code-verifier",
    ]
    for k in common_keys:
        v = storage.get(k)
        if isinstance(v, str) and v.strip():
            return k, v

    # å†å˜—è©¦æ‰€æœ‰åŒ…å« verifier çš„ key
    for k, v in storage.items():
        if not v:
            continue
        lk = str(k).lower()
        if "code-verifier" in lk or "code_verifier" in lk or "verifier" in lk:
            vv = str(v)
            if vv.strip():
                return k, vv

    return None, None


def _inject_cv_into_redirect_to(oauth_url: str, cv_key: str, cv_value: str) -> str:
    """æŠŠ code_verifier æ”¾åˆ° oauth_url çš„ redirect_to è£¡ï¼ˆä»¥ cv/cvk query å¸¶å›ï¼‰"""
    u = urlparse(oauth_url)
    qs = parse_qs(u.query)

    redirect_to = qs.get("redirect_to", [None])[0] or qs.get("redirectTo", [None])[0]
    if not redirect_to:
        return oauth_url

    ru = urlparse(redirect_to)
    rqs = parse_qs(ru.query)
    rqs["cv"] = [cv_value]
    rqs["cvk"] = [cv_key]

    new_redirect_to = urlunparse(ru._replace(query=urlencode(rqs, doseq=True)))

    if "redirect_to" in qs:
        qs["redirect_to"] = [new_redirect_to]
    elif "redirectTo" in qs:
        qs["redirectTo"] = [new_redirect_to]

    return urlunparse(u._replace(query=urlencode(qs, doseq=True)))


def handle_login():
    """è™•ç†ç™»å…¥æµç¨‹èˆ‡åŒæ­¥ï¼ˆSupabase OAuth code -> sessionï¼‰"""
    auth_client = st.session_state.get("auth_client")
    if auth_client is None:
        st.error("âŒ auth_client å°šæœªåˆå§‹åŒ–ï¼ˆst.session_state.auth_client ä¸å­˜åœ¨ï¼‰")
        st.stop()

    # 1) å˜—è©¦å¾æ—¢æœ‰ session æ¢å¾©
    try:
        session = auth_client.auth.get_session()
        if session and getattr(session, "user", None):
            st.session_state.user = session.user
            st.session_state.user_id = session.user.id
            update_supabase_session(session.access_token, session.refresh_token)
            return
    except Exception:
        pass

    # 2) è™•ç† OAuth å›èª¿ï¼šURL query å…§çš„ code + (cv/cvk)
    params = get_query_params()
    code = _first(params.get("code"))
    cv = _first(params.get("cv"))
    cvk = _first(params.get("cvk"))

    if code:
        try:
            # âœ… è‹¥æœ‰ cvï¼Œå°±å…ˆæŠŠ verifier æ”¾å› storageï¼Œè®“ exchange_code_for_session æ‰¾å¾—åˆ°
            if cv:
                if "supabase_auth_storage" not in st.session_state:
                    st.session_state.supabase_auth_storage = {}

                if cvk:
                    st.session_state.supabase_auth_storage[cvk] = cv

                # å†ä¿éšªï¼šè£œä¸€å€‹å¸¸è¦‹ keyï¼ˆä¸åŒç‰ˆæœ¬å¯èƒ½æœƒç”¨åˆ°ï¼‰
                st.session_state.supabase_auth_storage["supabase.auth.token-code-verifier"] = cv

            # âœ… é‡è¦ï¼šPython ç‰ˆç”¨ dict åƒæ•¸ï¼Œä¸è¦å‚³ç´”å­—ä¸²
            res = auth_client.auth.exchange_code_for_session({"auth_code": code})

            session = getattr(res, "session", None)
            user = getattr(res, "user", None)

            if user and session:
                st.session_state.user = user
                st.session_state.user_id = user.id
                update_supabase_session(session.access_token, session.refresh_token)

                clear_url()
                st.rerun()
            else:
                st.error("âŒ äº¤æ› session å¤±æ•—ï¼šres.user æˆ– res.session ç‚ºç©º")
                st.write(res)
                st.stop()

        except Exception as e:
            st.error(f"âŒ exchange_code_for_session å¤±æ•—ï¼š{e}")
            st.write("Query params:", params)
            st.stop()


def show_login_UI():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        st.title("ğŸ” å…¨çƒè³‡ç”¢ç®¡ç†ç³»çµ± V7.5")
        st.markdown("### è«‹ç™»å…¥ä»¥å­˜å–æ‚¨çš„å€‹äººè³‡ç”¢æ•¸æ“š")

        # é è¨­ä½¿ç”¨ secrets çš„é›²ç«¯ç¶²å€ï¼Œå¦å‰‡é€€å› localhostï¼ˆåƒ…æœ¬æ©Ÿæ¸¬è©¦ç”¨ï¼‰
        try:
            default_redirect_url = st.secrets["REDIRECT_URL"]
        except Exception:
            default_redirect_url = "http://localhost:8501"

        with st.expander("âš™ï¸ è¨­å®šç™»å…¥å›èª¿ç¶²å€ (è‹¥ç„¡æ³•ç™»å…¥è«‹æª¢æŸ¥)", expanded=False):
            redirect_url = st.text_input("Redirect URL", value=default_redirect_url).strip()

            if ("localhost" in redirect_url) or ("127.0.0.1" in redirect_url):
                st.warning(
                    "âš ï¸ ä½ ç›®å‰çš„ Redirect URL æ˜¯ localhostã€‚\n\n"
                    "å¦‚æœä½ éƒ¨ç½²åœ¨ Streamlit Cloudï¼Œé€™è£¡å¿…é ˆå¡«ä½ çš„é›²ç«¯ç¶²å€ï¼Œä¾‹å¦‚ï¼š\n"
                    "`https://my-wealth-v7.streamlit.app`"
                )

        if st.button("ğŸš€ ä½¿ç”¨ Google å¸³è™Ÿç™»å…¥", type="primary", use_container_width=True):
            try:
                res = st.session_state.auth_client.auth.sign_in_with_oauth(
                    {
                        "provider": "google",
                        "options": {
                            "redirect_to": redirect_url,
                            "query_params": {
                                "access_type": "offline",
                                "prompt": "consent select_account",
                            },
                        },
                    }
                )

                oauth_url = getattr(res, "url", None)
                if not oauth_url:
                    st.error("âŒ ç„¡æ³•å–å¾— OAuth URLï¼ˆres.url ç‚ºç©ºï¼‰")
                    st.stop()

                # âœ… å–å¾— code_verifierï¼ˆæ­¤æ™‚é€šå¸¸å·²è¢« SDK å­˜é€² storageï¼‰
                storage = st.session_state.get("supabase_auth_storage", {}) or {}
                cvk, cv = _find_code_verifier(storage)
                if not cvk or not cv:
                    st.error("âŒ æ‰¾ä¸åˆ° PKCE code_verifierï¼ˆsupabase_auth_storage å…§æ²’æœ‰ verifierï¼‰")
                    st.write("storage keys:", list(storage.keys()))
                    st.stop()

                # âœ… æŠŠ verifier æ³¨å…¥ redirect_to queryï¼Œè®“å›è·³æ™‚å¸¶å›ä¾†
                oauth_url2 = _inject_cv_into_redirect_to(oauth_url, str(cvk), str(cv))

                # âœ… åŒåˆ†é è‡ªå‹•è·³è½‰ï¼ˆé¿å…é–‹æ–°åˆ†é é€ æˆ session éºå¤±ï¼‰
                components.html(
                    f"""
                    <script>
                      window.location.href = {json.dumps(oauth_url2)};
                    </script>
                    """,
                    height=0,
                )

                # ä¿åº•ï¼šè‹¥ç€è¦½å™¨æ“‹ scriptï¼Œä»æä¾›å¯é»é€£çµ
                st.markdown(f"[ğŸ‘‰ è‹¥æœªè‡ªå‹•è·³è½‰ï¼Œè«‹é»æ­¤ç™»å…¥ Google]({oauth_url2})")
                st.stop()

            except Exception as e:
                st.error(f"âŒ åˆå§‹åŒ–å¤±æ•—: {e}")
                st.stop()


# --- åŸ·è¡Œç™»å…¥æª¢æŸ¥ ---
handle_login()

if not st.session_state.user:
    show_login_UI()
    st.stop()


# ==========================================
#      ğŸš€ ä¸»ç¨‹å¼é‚è¼¯ (ç™»å…¥æˆåŠŸå¾Œ)
# ==========================================

# å†æ¬¡ç¢ºä¿ Session åŒæ­¥ (é›™é‡ä¿éšªï¼Œé‡å°é é¢é‡æ–°æ•´ç†çš„æƒ…æ³)
if st.session_state.user:
    try:
        session = st.session_state.auth_client.auth.get_session()
        if session:
            update_supabase_session(session.access_token, session.refresh_token)
    except:
        pass

# åˆå§‹åŒ–è³‡æ–™
if 'transactions' not in st.session_state:
    with st.spinner('ğŸ”„ æ­£åœ¨è¼‰å…¥æ‚¨çš„åŠ å¯†è³‡æ–™...'):
        try:
            fetch_all_data()
        except Exception as e:
            # åˆå§‹åŒ–ç©ºçš„è³‡æ–™çµæ§‹ä»¥å…å ±éŒ¯ (é‡å°æ–°å¸³è™Ÿ)
            st.session_state.transactions = pd.DataFrame(columns=['id', 'user_id', 'é¡å‹', 'é¡åˆ¥', 'ä»£ç¢¼', 'æ•¸é‡', 'å–®åƒ¹', 'æ—¥æœŸ'])
            st.session_state.income_df = pd.DataFrame()
            st.session_state.liabilities_df = pd.DataFrame()
            st.session_state.liquidity_df = pd.DataFrame()
            st.session_state.snapshots_df = pd.DataFrame()
            st.session_state.settings = {"monthly_expense": 80000, "fire_mode": "ä¾æœˆé–‹éŠ·æ¨ç®— (25å€æ³•å‰‡)", "custom_target": 24000000}
            
            # å¦‚æœä¸æ˜¯å› ç‚ºç©ºè³‡æ–™è€Œæ˜¯æ¬Šé™éŒ¯èª¤ï¼Œæ‰é¡¯ç¤ºè­¦å‘Š
            if "policy" in str(e).lower() or "permission" in str(e).lower():
                st.error(f"è³‡æ–™è¼‰å…¥æ¬Šé™éŒ¯èª¤: {e}")

# éœæ…‹è³‡æ–™
PR_DATA_113 = {10: 33.0, 20: 38.6, 30: 44.0, 40: 49.3, 50: 54.6, 60: 61.4, 70: 71.9, 80: 88.5, 90: 131.2}

# --- 2. æ ¸å¿ƒæ•¸æ“šé‹ç®— ---
total_market_val, total_holding_cost, current_ex_rate = 0, 0, 32.5
holdings_df, detailed_tx_global = pd.DataFrame(), pd.DataFrame()
total_pnl, realized_all = 0, 0

# A. å³æ™‚æŠ•è³‡æ•¸æ“šè¨ˆç®—
if not st.session_state.transactions.empty:
    t_list = st.session_state.transactions['ä»£ç¢¼'].dropna().unique().tolist()
    prices, current_ex_rate = get_market_data(t_list)
    holdings_df, realized_all, detailed_tx_global = calculate_detailed_metrics(st.session_state.transactions, current_ex_rate)
    
    if not holdings_df.empty:
        # âœ… å°è‚¡ä»£ç¢¼ -> ä¸­æ–‡åç¨±ï¼ˆç¬¬ä¸€æ¬¡æœƒæŠ“å–å…¨é‡æ¸…å–®ä¸¦å¿«å–ï¼‰
        if 'é¡¯ç¤ºåç¨±' not in holdings_df.columns:
            holdings_df['é¡¯ç¤ºåç¨±'] = holdings_df['ä»£ç¢¼']
        mask_tw = holdings_df['é¡åˆ¥'] == 'å°è‚¡'
        if mask_tw.any():
            def _tw_disp(code):
                base = str(code).upper().replace('.TW', '').strip()
                name = get_tw_stock_name(base)
                return f"{name}({base})" if name else base
            holdings_df.loc[mask_tw, 'é¡¯ç¤ºåç¨±'] = holdings_df.loc[mask_tw, 'ä»£ç¢¼'].apply(_tw_disp)

        holdings_df['ç¾åƒ¹'] = holdings_df['ä»£ç¢¼'].map(prices).fillna(0)
        holdings_df['åŒ¯ç‡'] = holdings_df['é¡åˆ¥'].apply(lambda x: current_ex_rate if x != 'å°è‚¡' else 1.0)
        holdings_df['å¸‚å€¼(TWD)'] = holdings_df['ç¾åƒ¹'] * holdings_df['æŒå€‰æ•¸é‡'] * holdings_df['åŒ¯ç‡']
        holdings_df['æˆæœ¬(TWD)'] = holdings_df['å¹³å‡æˆæœ¬'] * holdings_df['æŒå€‰æ•¸é‡'] * holdings_df['åŒ¯ç‡']
        holdings_df['æç›Š(TWD)'] = holdings_df['å¸‚å€¼(TWD)'] - holdings_df['æˆæœ¬(TWD)']
        holdings_df['å ±é…¬ç‡'] = (holdings_df['æç›Š(TWD)'] / holdings_df['æˆæœ¬(TWD)'].replace(0, 1)) * 100
        
        total_market_val = holdings_df['å¸‚å€¼(TWD)'].sum()
        total_holding_cost = holdings_df['æˆæœ¬(TWD)'].sum()
        total_pnl = (total_market_val - total_holding_cost) + realized_all

# B. æµå‹•è³‡é‡‘èˆ‡è² å‚µè¨ˆç®—
total_liquidity = st.session_state.liquidity_df['amount'].sum() if not st.session_state.liquidity_df.empty else 0
total_liabilities = st.session_state.liabilities_df['amount'].sum() if not st.session_state.liabilities_df.empty else 0
net_assets = total_market_val + total_liquidity - total_liabilities

# --- è‡ªå‹•å­˜æª”ç•¶æ—¥å¿«ç…§ ---
save_daily_snapshot(total_market_val, total_liquidity, total_liabilities, net_assets)

# --- 3. ç²¾æº–æ™‚é–“æ®µå°æ¯”é‚è¼¯ ---
def get_historical_stats(days_back=None, start_date=None):
    if 'snapshots_df' not in st.session_state or st.session_state.snapshots_df.empty:
        return total_market_val, total_liquidity, total_liabilities, net_assets
    df_s = st.session_state.snapshots_df.copy()
    df_s['snapshot_date'] = pd.to_datetime(df_s['snapshot_date']).dt.date
    target_date = start_date if start_date else (datetime.now().date() - timedelta(days=days_back if days_back else 0))
    past_records = df_s[df_s['snapshot_date'] <= target_date]
    rec = past_records.iloc[0] if not past_records.empty else df_s.iloc[-1]
    return rec['market_value'], rec['liquidity_amount'], rec['liabilities_amount'], rec['net_assets']

# --- 4. å´é‚Šæ¬„ï¼šè³‡ç”¢è¼¸å…¥ ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ é›²ç«¯è³‡ç”¢ç®¡ç† V7.5")
    
    if st.session_state.user:
        user_email = st.session_state.user.email
        st.caption(f"ğŸ‘¤ å·²ç™»å…¥: {user_email}")
        if st.button("ç™»å‡ºç³»çµ±", type="secondary"):
            # ç™»å‡º
            st.session_state.auth_client.auth.sign_out()
            st.session_state.clear()
            st.rerun()
    st.divider()

    with st.form("trade_form", clear_on_submit=True):
        st.subheader("ğŸ“ æ–°å¢æŠ•è³‡äº¤æ˜“")
        t_type = st.radio("äº¤æ˜“é¡å‹", ["è²·å…¥", "è³£å‡º"], horizontal=True)
        t_cat = st.selectbox("è³‡ç”¢é¡åˆ¥", ["å°è‚¡", "ç¾è‚¡", "åŠ å¯†è²¨å¹£"])
        t_ticker = st.text_input("æ¨™çš„ä»£ç¢¼ (å¦‚ 2330, TSLA)").upper().strip()

        # å°è‚¡ä»£ç¢¼å³æ™‚é¡¯ç¤ºä¸­æ–‡åç¨±ï¼ˆç¬¬ä¸€æ¬¡æœƒæŠ“å–å…¨é‡æ¸…å–®ä¸¦å¿«å–ï¼‰
        if t_cat == "å°è‚¡" and t_ticker:
            tw_name = get_tw_stock_name(t_ticker)
            if tw_name:
                st.caption(f"ğŸ“Œ è‚¡ç¥¨åç¨±ï¼š{tw_name}")
            else:
                st.caption("âš ï¸ æŸ¥ç„¡æ­¤å°è‚¡ä»£ç¢¼ï¼ˆä»å¯å­˜å…¥ï¼‰")
        t_qty = st.number_input("æ•¸é‡", min_value=0.0, format="%.4f")
        t_price = st.number_input("å–®åƒ¹", min_value=0.0, format="%.4f")
        t_date = st.date_input("äº¤æ˜“æ—¥æœŸ", datetime.now())
        if st.form_submit_button("âœ… å­˜å…¥é›²ç«¯æ•¸æ“šåº«"):
            if t_ticker and t_qty > 0:
                data = {"user_id": st.session_state.user_id, "é¡å‹": t_type, "é¡åˆ¥": t_cat, "ä»£ç¢¼": t_ticker, "æ•¸é‡": t_qty, "å–®åƒ¹": t_price, "æ—¥æœŸ": t_date.isoformat()}
                data_client.table("transactions").insert(data).execute()
                fetch_all_data(); st.rerun()

# --- 5. ä¸»ç•«é¢å…§å®¹ ---
tab1, tab_liab, tab2, tab3 = st.tabs(["ğŸ“Š è³‡ç”¢å„€è¡¨æ¿", "ğŸ“‰ è² å‚µç®¡ç†", "ğŸ’° æ”¶å…¥èˆ‡æµå‹•è³‡é‡‘", "ğŸ¯ FIRE è¦åŠƒ"])

# --- Tab 1: è³‡ç”¢å„€è¡¨æ¿ ---
with tab1:
    title_col, filter_col = st.columns([3, 1])
    with title_col: st.subheader("ğŸ“Š å…¨çƒè³‡ç”¢æ¦‚æ³")
    with filter_col:
        time_range = st.selectbox("å°æ¯”åŸºæº–é»", ["ä¸å°æ¯”", "æ—¥ (å‰ä¸€æ—¥)", "æœˆ (å‰ä¸€æœˆ)", "å¹´ (å‰ä¸€å¹´)", "è‡ªå®šç¾©"], label_visibility="collapsed")
    
    # åŸ·è¡Œå°æ¯”é‚è¼¯
    if time_range == "æ—¥ (å‰ä¸€æ—¥)": hist_m, hist_l, hist_liab, hist_net = get_historical_stats(days_back=1)
    elif time_range == "æœˆ (å‰ä¸€æœˆ)": hist_m, hist_l, hist_liab, hist_net = get_historical_stats(days_back=30)
    elif time_range == "å¹´ (å‰ä¸€å¹´)": hist_m, hist_l, hist_liab, hist_net = get_historical_stats(days_back=365)
    elif time_range == "è‡ªå®šç¾©":
        d_range = st.date_input("é–‹å§‹æ—¥æœŸ", value=(datetime.now() - timedelta(days=7)), label_visibility="collapsed")
        hist_m, hist_l, hist_liab, hist_net = get_historical_stats(start_date=d_range)
    else: hist_m, hist_l, hist_liab, hist_net = total_market_val, total_liquidity, total_liabilities, net_assets

    net_delta, liq_delta, mkt_delta = net_assets - hist_net, total_liquidity - hist_l, total_market_val - hist_m

    col_m1, col_m2, col_m3, col_m4, col_m5 = st.columns(5)
    delta_tag = f"({time_range})" if time_range != "ä¸å°æ¯”" else None
    
    with col_m1: st.metric("æ·¨è³‡ç”¢ (TWD)", f"NT$ {net_assets:,.0f}", delta=f"{net_delta:,.0f}" if delta_tag else None, help=delta_tag)
    with col_m2: st.metric("ç›®å‰æµå‹•è³‡é‡‘", f"NT$ {total_liquidity:,.0f}", delta=f"{liq_delta:,.0f}" if delta_tag else None)
    with col_m3:
        m_c = "#D62728" if mkt_delta >= 0 else "#2CA02C"
        delta_str = f"{mkt_delta:+,.0f}" if delta_tag else ""
        st.markdown(f"<p style='color:gray; font-size:16px;'>æŠ•è³‡ç¸½å¸‚å€¼</p><h2 style='margin-top:-15px;'>NT$ {total_market_val:,.0f}</h2><p style='color:{m_c}; font-size:14px; margin-top:-10px;'>{delta_str} <span style='color:gray;'>| æˆæœ¬: {total_holding_cost:,.0f}</span></p>", unsafe_allow_html=True)
    with col_m4:
        p_c = "#D62728" if total_pnl >= 0 else "#2CA02C"
        st.markdown(f"<p style='color:gray; font-size:16px;'>ç´¯ç©ç¸½æç›Š</p><h2 style='color:{p_c}; margin-top:-15px;'>NT$ {total_pnl:,.0f}</h2><p style='color:{p_c}; font-size:14px; margin-top:-10px;'>{(total_pnl/total_holding_cost*100 if total_holding_cost else 0):+.2f}% (ROI)</p>", unsafe_allow_html=True)
    with col_m5: st.metric("ç¸½è² å‚µé¡", f"NT$ {total_liabilities:,.0f}", delta=f"-{total_liabilities:,.0f}" if total_liabilities > 0 else None, delta_color="inverse")

    st.divider()

    c_l, c_r = st.columns([2, 1])
    with c_l:
        if not st.session_state.snapshots_df.empty:
            df_plot = st.session_state.snapshots_df.sort_values('snapshot_date')
            
            # 1. å®šç¾©ä¸­æ–‡åç¨±å°ç…§è¡¨
            name_map = {
                'net_assets': 'æ·¨è³‡ç”¢',
                'market_value': 'å¸‚å ´åƒ¹å€¼',
                'liquidity_amount': 'æµå‹•é‡‘é¡'
            }
            
            # 2. ç¹ªåœ–
            fig = px.line(
                df_plot, 
                x='snapshot_date', 
                y=list(name_map.keys()), 
                title="è³‡ç”¢æ­·å²è¶¨å‹¢"
            )
            
            # 3. å¼·åˆ¶ä¿®æ”¹ç·šæ¢åç¨±
            fig.for_each_trace(lambda t: t.update(name = name_map.get(t.name, t.name)))
            
            # 4. ä¿®æ”¹åœ–ä¾‹æ¨™é¡Œ
            fig.update_layout(legend_title_text='è³‡ç”¢ç¨®é¡')
            
            st.plotly_chart(fig, use_container_width=True)
    with c_r:
        pie_df = pd.DataFrame({"é …ç›®": ["æŠ•è³‡", "æµå‹•è³‡é‡‘", "è² å‚µ"], "é‡‘é¡": [total_market_val, total_liquidity, total_liabilities]})
        st.plotly_chart(px.pie(pie_df, values='é‡‘é¡', names='é …ç›®', hole=0.4, color_discrete_sequence=["#ff7f0e", "#2ca02c", "#d62728"]), use_container_width=True)

    st.divider()
    asset_tabs = st.tabs(["ğŸ‡¹ğŸ‡¼ å°è‚¡", "ğŸ‡ºğŸ‡¸ ç¾è‚¡", "ğŸª™ åŠ å¯†è²¨å¹£"])
    cat_map = {"å°è‚¡": "ğŸ‡¹ğŸ‡¼ å°è‚¡", "ç¾è‚¡": "ğŸ‡ºğŸ‡¸ ç¾è‚¡", "åŠ å¯†è²¨å¹£": "ğŸª™ åŠ å¯†è²¨å¹£"}
    for i, (internal_cat, display_cat) in enumerate(cat_map.items()):
        with asset_tabs[i]:
            df_sub = holdings_df[holdings_df['é¡åˆ¥'] == internal_cat] if not holdings_df.empty else pd.DataFrame()
            if not df_sub.empty:
                st.plotly_chart(px.bar(df_sub.sort_values('å¸‚å€¼(TWD)'), x='å¸‚å€¼(TWD)', y='é¡¯ç¤ºåç¨±', orientation='h', text_auto='.2s', color='å¸‚å€¼(TWD)', title=f"{internal_cat} æ¨™çš„å æ¯”"), use_container_width=True)
                st.dataframe(df_sub[['é¡¯ç¤ºåç¨±', 'æŒå€‰æ•¸é‡', 'å¹³å‡æˆæœ¬', 'ç¾åƒ¹', 'å¸‚å€¼(TWD)', 'æç›Š(TWD)', 'å ±é…¬ç‡']].style.format({'å¸‚å€¼(TWD)': '{:,.0f}', 'æç›Š(TWD)': '{:,.0f}', 'å ±é…¬ç‡': '{:+.2f}%', 'ç¾åƒ¹': '{:,.2f}', 'å¹³å‡æˆæœ¬': '{:,.2f}'}), use_container_width=True)
                s_v, s_p, s_c = df_sub['å¸‚å€¼(TWD)'].sum(), df_sub['æç›Š(TWD)'].sum(), df_sub['æˆæœ¬(TWD)'].sum()
                sc1, sc2, sc3 = st.columns(3)
                sc1.metric("ç¸½å¸‚å€¼", f"NT$ {s_v:,.0f}")
                if internal_cat != "å°è‚¡": sc1.caption(f"ğŸ“ æ›ç®—åŒ¯ç‡: 1 USD = {current_ex_rate:.2f} TWD")
                sc2.metric("ç¸½æç›Š", f"NT$ {s_p:,.0f}", delta=f"{s_p:,.0f}")
                sc3.metric("å ±é…¬ç‡", f"{(s_p/s_c*100 if s_c != 0 else 0):.2f}%")

# --- Tab: è² å‚µç®¡ç† ---
with tab_liab:
    st.header("ğŸ“‰ è² å‚µèˆ‡è²¸æ¬¾ç®¡ç†")
    l_col1, l_col2 = st.columns([1, 1.5])
    with l_col1:
        st.subheader("ğŸ–‹ï¸ ç´€éŒ„è² å‚µé …ç›®")
        with st.form("liab_form"):
            l_cat, l_name = st.selectbox("è² å‚µé¡åˆ¥", ["å°è‚¡èè³‡", "ç¾è‚¡èè³‡", "ä¿¡è²¸", "å…¶ä»–"]), st.text_input("é …ç›®åç¨±")
            l_amt = st.number_input("æ¬ æ¬¾é‡‘é¡ (TWD)", min_value=0.0)
            if st.form_submit_button("ğŸ’¾ å„²å­˜è² å‚µ"):
                data_client.table("liabilities").upsert({"user_id": st.session_state.user_id, "category": l_cat, "name": l_name if l_name else l_cat, "amount": l_amt, "updated_at": datetime.now().isoformat()}, on_conflict='user_id, name').execute()
                fetch_all_data(); st.rerun()
    with l_col2:
        st.subheader("ğŸ“‹ è² å‚µæ˜ç´°ï¼ˆå¯ç·¨è¼¯ / åˆªé™¤ï¼‰")
        if st.session_state.liabilities_df.empty:
            st.info("ç›®å‰å°šç„¡è² å‚µè³‡æ–™")
        else:
            liab_src = st.session_state.liabilities_df.copy()

            # ä¸Šå‚³æ™‚é–“ / æ›´æ–°æ™‚é–“ï¼šåªé¡¯ç¤ºåˆ°ã€Œå¹´-æœˆ-æ—¥ æ™‚:åˆ†ã€
            if "updated_at" in liab_src.columns:
                liab_src["updated_at"] = _format_dt_series(liab_src["updated_at"])

            disp = liab_src.copy()
            show_cols = []
            if "id" in disp.columns:
                show_cols.append("id")
            for c in ["category", "name", "amount", "updated_at"]:
                if c in disp.columns:
                    show_cols.append(c)
            disp = disp[show_cols].rename(columns={
                "category": "è² å‚µé¡åˆ¥",
                "name": "é …ç›®åç¨±",
                "amount": "é‡‘é¡(TWD)",
                "updated_at": "æ›´æ–°æ™‚é–“",
            })

            edited_liab = st.data_editor(
                disp,
                use_container_width=True,
                num_rows="dynamic",
                disabled=[c for c in ["id", "æ›´æ–°æ™‚é–“"] if c in disp.columns],
                key="liab_editor",
            )

            if st.button("ğŸ’¾ å„²å­˜è² å‚µè¡¨æ ¼ä¿®æ”¹", key="save_liab_btn"):
                try:
                    _sync_liabilities(liab_src, edited_liab)
                    fetch_all_data()
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ å„²å­˜è² å‚µä¿®æ”¹å¤±æ•—ï¼š{e}")

# --- Tab 2: æ”¶å…¥èˆ‡æµå‹•è³‡é‡‘ (æ•´åˆæ‚¨çš„ PR åˆ†æèˆ‡æˆ‘çš„å¸³æˆ¶ç®¡ç†) ---
with tab2:
    st.header("ğŸ’° æ”¶å…¥èˆ‡æµå‹•è³‡é‡‘ç®¡ç†")
    
    # ä¸ŠåŠéƒ¨ï¼šæµå‹•è³‡é‡‘å¸³æˆ¶ç®¡ç†
    st.subheader("ğŸ’µ æµå‹•è³‡é‡‘å¸³æˆ¶æ˜ç´° (TWD)")
    liq_col1, liq_col2 = st.columns([1, 1.5])
    with liq_col1:
        with st.form("liquidity_form"):
            acc_name, acc_amt = st.text_input("å¸³æˆ¶åç¨±"), st.number_input("é‡‘é¡ (TWD)", min_value=0.0)
            if st.form_submit_button("ğŸ’¾ å„²å­˜å¸³æˆ¶"):
                if acc_name:
                    data_client.table("liquidity").upsert({"user_id": st.session_state.user_id, "account_name": acc_name, "amount": acc_amt, "updated_at": datetime.now().isoformat()}, on_conflict='user_id, account_name').execute()
                    fetch_all_data(); st.rerun()
    with liq_col2:
        st.subheader("ğŸ“‹ å¸³æˆ¶æ˜ç´°ï¼ˆå¯ç·¨è¼¯ / åˆªé™¤ï¼‰")
        if st.session_state.liquidity_df.empty:
            st.info("ç›®å‰å°šç„¡æµå‹•è³‡é‡‘å¸³æˆ¶è³‡æ–™")
        else:
            liq_src = st.session_state.liquidity_df.copy()

            # ä¸Šå‚³æ™‚é–“ / æ›´æ–°æ™‚é–“ï¼šåªé¡¯ç¤ºåˆ°ã€Œå¹´-æœˆ-æ—¥ æ™‚:åˆ†ã€
            if "updated_at" in liq_src.columns:
                liq_src["updated_at"] = _format_dt_series(liq_src["updated_at"])

            disp = liq_src.copy()
            show_cols = []
            if "id" in disp.columns:
                show_cols.append("id")
            for c in ["account_name", "amount", "updated_at"]:
                if c in disp.columns:
                    show_cols.append(c)
            disp = disp[show_cols].rename(columns={
                "account_name": "å¸³æˆ¶åç¨±",
                "amount": "é‡‘é¡(TWD)",
                "updated_at": "æ›´æ–°æ™‚é–“",
            })

            edited_liq = st.data_editor(
                disp,
                use_container_width=True,
                num_rows="dynamic",
                disabled=[c for c in ["id", "æ›´æ–°æ™‚é–“"] if c in disp.columns],
                key="liq_editor",
            )

            if st.button("ğŸ’¾ å„²å­˜æµå‹•è³‡é‡‘è¡¨æ ¼ä¿®æ”¹", key="save_liq_btn"):
                try:
                    _sync_liquidity(liq_src, edited_liq)
                    fetch_all_data()
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ å„²å­˜æµå‹•è³‡é‡‘ä¿®æ”¹å¤±æ•—ï¼š{e}")

            st.metric("ç¸½æµå‹•è³‡é‡‘åŠ ç¸½", f"NT$ {total_liquidity:,.0f}")

    st.divider()

    # ä¸‹åŠéƒ¨ï¼šæ¢å¾©æ‚¨çš„å®Œæ•´æ”¶å…¥ç®¡ç†é‚è¼¯
    st.subheader("ğŸ’° æ”¶å…¥èˆ‡è–ªè³‡ PR åˆ†æ")
    col_in1, col_in2 = st.columns(2)
    with col_in1:
        st.subheader("ğŸ–‹ï¸ ç´€éŒ„æ–°æ”¶å…¥")
        in_mode = st.radio("è¼¸å…¥æ–¹å¼", ["è–ªè³‡+çé‡‘", "ç›´æ¥å¹´æ”¶"], horizontal=True)
        with st.form("income_form"):
            if in_mode == "è–ªè³‡+çé‡‘":
                m = st.number_input("æœˆè–ª", min_value=0, step=1000)
                b = st.number_input("çé‡‘/å…¶ä»–", min_value=0, step=1000)
                ann = (m * 12) + b
                st.info(f"è¨ˆç®—å‡ºçš„ç¸½å¹´æ”¶ï¼šNT$ {ann:,.0f}")
            else:
                ann = st.number_input("å¹´æ”¶ç¸½è¨ˆ", min_value=0, step=10000)
            note = st.text_input("å‚™è¨» (ä¾‹å¦‚: 2026å¹´è–ª)")
            if st.form_submit_button("ğŸ’¾ å„²å­˜æ”¶å…¥ç´€éŒ„"):
                data_client.table("income_history").insert({"user_id": st.session_state.user_id, "ç´€éŒ„æ—¥æœŸ": datetime.now().isoformat(), "å¹´æ”¶å…¥": ann, "å‚™è¨»": note}).execute()
                fetch_all_data(); st.rerun()

    with col_in2:
        st.subheader("ğŸ“ˆ æ­·å²æ”¶å…¥èˆ‡ PR")
        if not st.session_state.income_df.empty:
            curr_ann = st.session_state.income_df['å¹´æ”¶å…¥'].iloc[-1]
            ann_wan = curr_ann / 10000
            user_pr = 0
            for pr, val in sorted(PR_DATA_113.items()):
                if ann_wan >= val: user_pr = pr
            st.metric("ç•¶å‰ç´€éŒ„å¹´æ”¶", f"NT$ {curr_ann:,.0f}", help="ä»¥æœ€å¾Œä¸€ç­†ç´€éŒ„ç‚ºæº–")
            st.markdown(f"æ‚¨çš„å¹´è–ªé ˜å…ˆå…¨å°ç´„ **{user_pr}%** çš„å—è–ªéšç´šã€‚")
            
            st.write("æ­·å²ç´€éŒ„ï¼ˆå¯ç·¨è¼¯ / åˆªé™¤ï¼‰")
            in_src = st.session_state.income_df.copy()

            # ä¸Šå‚³æ™‚é–“ï¼šåªé¡¯ç¤ºåˆ°ã€Œå¹´-æœˆ-æ—¥ æ™‚:åˆ†ã€
            if "ç´€éŒ„æ—¥æœŸ" in in_src.columns:
                in_src["ä¸Šå‚³æ™‚é–“"] = _format_dt_series(in_src["ç´€éŒ„æ—¥æœŸ"])
            else:
                in_src["ä¸Šå‚³æ™‚é–“"] = ""

            disp_in = in_src.copy()
            show_cols = []
            if "id" in disp_in.columns:
                show_cols.append("id")
            if "ä¸Šå‚³æ™‚é–“" in disp_in.columns:
                show_cols.append("ä¸Šå‚³æ™‚é–“")
            for c in ["å¹´æ”¶å…¥", "å‚™è¨»"]:
                if c in disp_in.columns:
                    show_cols.append(c)
            disp_in = disp_in[show_cols]

            edited_in = st.data_editor(
                disp_in,
                num_rows="dynamic",
                use_container_width=True,
                disabled=[c for c in ["id", "ä¸Šå‚³æ™‚é–“"] if c in disp_in.columns],
                key="income_editor",
            )

            if st.button("ğŸ’¾ å„²å­˜æ”¶å…¥è¡¨æ ¼ä¿®æ”¹", key="save_income_btn"):
                try:
                    _sync_income_history(in_src, edited_in)
                    fetch_all_data()
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ å„²å­˜æ”¶å…¥ä¿®æ”¹å¤±æ•—ï¼š{e}")

# --- Tab 3: FIRE è¦åŠƒ (æ¢å¾©æ‚¨çš„å®Œæ•´ä»‹é¢èˆ‡èªªæ˜) ---
with tab3:
    st.header("ğŸ¯ FIRE é€€ä¼‘è¦åŠƒ")
    col_f1, col_f2 = st.columns([1, 1.5])
    
    with col_f1:
        st.subheader("âš™ï¸ è¨­å®šé€€ä¼‘ç›®æ¨™")
        settings = st.session_state.settings
        f_mode = st.radio("ç›®æ¨™è¨­å®šæ–¹å¼", ["ä¾æœˆé–‹éŠ·æ¨ç®— (25å€æ³•å‰‡)", "è‡ªå®šç¾©ç›®æ¨™"], 
                          index=0 if settings.get('fire_mode') == "ä¾æœˆé–‹éŠ·æ¨ç®— (25å€æ³•å‰‡)" else 1)
        
        if f_mode == "ä¾æœˆé–‹éŠ·æ¨ç®— (25å€æ³•å‰‡)":
            m_exp = st.number_input("é€€ä¼‘å¾Œé ä¼°æ¯æœˆç”Ÿæ´»è²»", value=int(settings.get('monthly_expense', 80000)), step=1000)
            ann_exp = m_exp * 12
            fire_target = ann_exp * 25
            st.info(f"ğŸ”¹ é ä¼°å¹´æ”¯å‡ºï¼šNT$ {ann_exp:,.0f}")
            st.markdown(f"ğŸš© è‡ªå‹•ç®—å‡ºç›®æ¨™ï¼š**NT$ {fire_target:,.0f}**")
        else:
            fire_target = st.number_input("è‡ªå®šç¾©ç›®æ¨™é‡‘é¡", value=int(settings.get('custom_target', 15000000)), step=100000)
            m_exp = settings.get('monthly_expense', 80000)

        with st.expander("ğŸ’¡ ç‚ºä½•æ˜¯ 25 å€ï¼Ÿ"):
            st.write("é€™æºè‡ªã€4% æ³•å‰‡ã€ï¼šç•¶è³‡ç”¢é”åˆ°å¹´æ”¯å‡ºçš„ 25 å€ï¼Œæ¯å¹´æå– 4% ç”Ÿæ´»è²»ï¼Œè³‡é‡‘æœ‰æ¥µé«˜æ©Ÿç‡æ°¸é é ˜ä¸å®Œã€‚")
        
        if st.button("ğŸ’¾ å„²å­˜é€€ä¼‘è¨­å®š"):
            data_client.table("user_settings").upsert({"user_id": st.session_state.user_id, "monthly_expense": m_exp, "custom_target": fire_target, "fire_mode": f_mode}).execute()
            fetch_all_data(); st.rerun()

    with col_f2:
        st.subheader("ğŸ“Š è²¡å¯Œæ£®æ—æˆé•·é€²åº¦")
        if fire_target > 0:
            # é€™è£¡æ”¹ç”¨æ·¨è³‡ç”¢ net_assets ä½œç‚ºé”æˆç‡åŸºæº–ï¼Œæ›´ç²¾ç¢º
            rate = (net_assets / fire_target * 100)
            missing = fire_target - net_assets
            
            st.write(f"### ç›®å‰æ·¨è³‡ç”¢ï¼šNT$ {net_assets:,.0f}")
            st.write(f"### ç›®æ¨™é‡‘é¡ï¼šNT$ {fire_target:,.0f}")
            
            # æˆé•·éšæ®µèˆ‡ Icon (æ¢å¾©æ‚¨çš„å®Œæ•´æ¸…å–®)
            stages = [("ç¨®å­", "ğŸ«˜"), ("èŒèŠ½", "ğŸŒ±"), ("å¹¼è‹—", "ğŸŒ¿"), ("èŒå£¯", "ğŸª´"), ("ç¹è‘‰", "ğŸƒ"), 
                      ("æç¹è‘‰èŒ‚", "ğŸŒ¿âœ¨"), ("æ—æœ¨", "ğŸŒ²"), ("æ·±æ ¹", "ğŸŒ³"), ("ç¢©æœ", "ğŸğŸŒ³"), ("åœ“æ»¿", "ğŸ†ğŸŒ³"), ("æ£®æ—", "ğŸŒ³ğŸŒ²ğŸŠ")]
            idx = min(int(max(0, rate) // 10), 10)
            name, icon = stages[idx]
            
            st.markdown(f"<div style='text-align: center; background-color: #f0f2f6; padding: 20px; border-radius: 10px;'>"
                        f"<h1 style='font-size: 80px; margin: 0;'>{icon}</h1>"
                        f"<h2 style='margin: 0;'>ç­‰ç´šï¼š{name}</h2>"
                        f"</div>", unsafe_allow_html=True)
            
            st.divider()
            st.progress(min(max(rate/100, 0.0), 1.0))
            
            c_r1, c_r2 = st.columns(2)
            c_r1.metric("FIRE é”æˆç‡", f"{rate:.2f}%")
            c_r2.metric("å°šæ¬ é‡‘é¡", f"NT$ {max(0, missing):,.0f}", delta=f"-{max(0, missing):,.0f}", delta_color="inverse")

# --- åº•éƒ¨æµæ°´å¸³ ---
st.divider()
st.subheader("ğŸ“œ æ­·å²äº¤æ˜“ç·¨è¼¯")
if st.session_state.transactions.empty:
    st.info("å°šç„¡äº¤æ˜“ç´€éŒ„")
else:
    tx_src = st.session_state.transactions.copy()

    # æ—¥æœŸæ¬„ä½çµ±ä¸€æˆ dateï¼Œæ–¹ä¾¿ç›´æ¥ç·¨è¼¯
    if "æ—¥æœŸ" in tx_src.columns:
        tx_src["æ—¥æœŸ"] = pd.to_datetime(tx_src["æ—¥æœŸ"], errors="coerce").dt.date

    # å°è‚¡ä»£ç¢¼ -> ä¸­æ–‡åç¨±ï¼ˆé¡¯ç¤ºç”¨ï¼Œä¸å›å¯«ï¼‰
    tx_src["å°è‚¡åç¨±"] = ""
    try:
        if "é¡åˆ¥" in tx_src.columns and "ä»£ç¢¼" in tx_src.columns:
            mask = tx_src["é¡åˆ¥"] == "å°è‚¡"
            if mask.any():
                def _tw_name_only(code):
                    base = str(code).upper().replace(".TW", "").strip()
                    return get_tw_stock_name(base) or ""
                tx_src.loc[mask, "å°è‚¡åç¨±"] = tx_src.loc[mask, "ä»£ç¢¼"].apply(_tw_name_only)
    except Exception:
        pass

    show_cols = [c for c in ["id", "æ—¥æœŸ", "é¡å‹", "é¡åˆ¥", "ä»£ç¢¼", "å°è‚¡åç¨±", "æ•¸é‡", "å–®åƒ¹"] if c in tx_src.columns]
    disp_tx = tx_src[show_cols].sort_values("æ—¥æœŸ", ascending=False)

    edited_tx = st.data_editor(
        disp_tx,
        use_container_width=True,
        num_rows="dynamic",
        disabled=[c for c in ["id", "å°è‚¡åç¨±"] if c in disp_tx.columns],
        key="tx_editor",
    )

    if st.button("ğŸ’¾ å„²å­˜äº¤æ˜“è¡¨æ ¼ä¿®æ”¹", key="save_tx_btn"):
        try:
            _sync_transactions(tx_src, edited_tx)
            fetch_all_data()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ å„²å­˜äº¤æ˜“ä¿®æ”¹å¤±æ•—ï¼š{e}")
